<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>尚硅谷hadoop笔记 | FluffySpoooooonge!!!</title>
  <meta name="description" content="Hadoop概述：Hadoop: Apache基金会的分布式基础架构解决海量数据存储 和 分析计算 问题 MySQL处理极限数据量在百万级别数据查询，大概1TB量Hadoop:存：HDFS; 算：MapReduce hadoop的组成：1.x:MapReduce:  计算 + 资源调度HDFS: 数据存储 2.x:  解耦，实现计算模块可插拔MapReduce: 计算Yarn: 资源调度HDFS：">
<meta name="keywords" content="学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="尚硅谷hadoop笔记">
<meta property="og:url" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;index.html">
<meta property="og:site_name" content="FluffySpoooooooonge !!!">
<meta property="og:description" content="Hadoop概述：Hadoop: Apache基金会的分布式基础架构解决海量数据存储 和 分析计算 问题 MySQL处理极限数据量在百万级别数据查询，大概1TB量Hadoop:存：HDFS; 算：MapReduce hadoop的组成：1.x:MapReduce:  计算 + 资源调度HDFS: 数据存储 2.x:  解耦，实现计算模块可插拔MapReduce: 计算Yarn: 资源调度HDFS：">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;Yarn架构.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce大概意思.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;大数据技术生态体系.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;HDFS上传流程.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;HDFS下载流程.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce的数据流.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;数据切片与MapTask并行度决定机制.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;Shuffle机制.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce详细工作流程一.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce详细工作流程二.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce开发总结1.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce开发总结2.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce开发总结3.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce开发总结4.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;MapReduce开发总结5.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;HDFS-HA故障转移机制.png">
<meta property="og:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;YARN-HA工作机制.png">
<meta property="og:updated_time" content="2020-05-27T15:58:58.378Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;www.fluffysponge.fun&#x2F;2020&#x2F;05&#x2F;01&#x2F;%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0&#x2F;Yarn架构.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://www.fluffysponge.fun/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/index.html">
  
    <link rel="alternate" href="/atom.xml" title="FluffySpoooooooonge !!!" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  <link rel="stylesheet" href="/css/style.css">
  
  
  
  
</head>


<body class="main-center theme-black# 主题颜色 theme-black theme-blue theme-green theme-purple" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/InstantCWeed" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">InstantCWeed</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Student</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> BeiJing, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-books">
          <a href="/books">
            
            <i class="icon icon-book-fill"></i>
            
            <span class="menu-title">书单</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">友链</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/InstantCWeed" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://weibo.com/u/3100744741" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="http://huaban.com/" target="_blank" title="Huaban" data-toggle=tooltip data-placement=top><i class="icon icon-huaban"></i></a></li>
        
        <li><a href="https://www.behance.net/" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>人处在一种默默奋斗的状态，精神就会从琐碎生活中得到升华。</p>
            </div>
        </div>
    </div>
</div>

    
      

    
      
  <div class="widget">
    <h3 class="widget-title">标签</h3>
    <div class="widget-body">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java%E5%86%85%E5%AE%B9%E7%B4%A2%E5%BC%95/" rel="tag">Java内容索引</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a><span class="tag-list-count">21</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo%E4%BD%BF%E7%94%A8/" rel="tag">hexo使用</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%B7%E9%A2%98/" rel="tag">刷题</a><span class="tag-list-count">61</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%B7%E9%A2%98%E7%9B%AE%E5%BD%95/" rel="tag">刷题目录</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E7%A1%80/" rel="tag">基础</a><span class="tag-list-count">29</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">学习笔记</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/" rel="tag">工具使用</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/" rel="tag">工具学习</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F/" rel="tag">广告系统</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B%E7%96%91%E6%83%91/" rel="tag">编程疑惑</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/" rel="tag">解决问题</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%BB%E4%B9%A6/" rel="tag">读书</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Java%E5%86%85%E5%AE%B9%E7%B4%A2%E5%BC%95/" style="font-size: 13px;">Java内容索引</a> <a href="/tags/hadoop/" style="font-size: 13.67px;">hadoop</a> <a href="/tags/hexo%E4%BD%BF%E7%94%A8/" style="font-size: 13.5px;">hexo使用</a> <a href="/tags/%E5%88%B7%E9%A2%98/" style="font-size: 14px;">刷题</a> <a href="/tags/%E5%88%B7%E9%A2%98%E7%9B%AE%E5%BD%95/" style="font-size: 13.17px;">刷题目录</a> <a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 13.83px;">基础</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="font-size: 13.5px;">学习笔记</a> <a href="/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/" style="font-size: 13.17px;">工具使用</a> <a href="/tags/%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/" style="font-size: 13.17px;">工具学习</a> <a href="/tags/%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F/" style="font-size: 13px;">广告系统</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E7%96%91%E6%83%91/" style="font-size: 13.17px;">编程疑惑</a> <a href="/tags/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/" style="font-size: 13.33px;">解决问题</a> <a href="/tags/%E8%AF%BB%E4%B9%A6/" style="font-size: 13.33px;">读书</a> <a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 13.33px;">面试</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a><span class="archive-list-count">23</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a><span class="archive-list-count">49</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a><span class="archive-list-count">44</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2020/05/27/IDEA%E4%B8%8A%E6%89%BE%E5%8D%9A%E5%AE%A2%E5%85%B1%E5%90%8C%E5%A5%BD%E5%8F%8B%E6%A1%88%E4%BE%8B/" class="title">IDEA上找博客共同好友案例</a>
              </p>
              <p class="item-date">
                <time datetime="2020-05-27T06:48:26.000Z" itemprop="datePublished">2020-05-27</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2020/05/27/IDEA%E4%B8%8AT%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E6%A1%88%E4%BE%8B/" class="title">IDEA上T倒排索引案例</a>
              </p>
              <p class="item-date">
                <time datetime="2020-05-27T06:47:10.000Z" itemprop="datePublished">2020-05-27</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2020/05/27/IDEA%E4%B8%8ATopN%E6%A1%88%E4%BE%8B/" class="title">IDEA上TopN案例</a>
              </p>
              <p class="item-date">
                <time datetime="2020-05-27T06:42:10.000Z" itemprop="datePublished">2020-05-27</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2020/05/24/IDEA%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97ETL%E5%AE%9E%E6%93%8D%E6%A1%88%E4%BE%8B-%E5%A4%8D%E6%9D%82%E7%89%88/" class="title">IDEA数据清洗ETL实操案例-复杂版</a>
              </p>
              <p class="item-date">
                <time datetime="2020-05-24T15:09:03.000Z" itemprop="datePublished">2020-05-24</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2020/05/24/IDEA%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97ETL%E5%AE%9E%E6%93%8D%E6%A1%88%E4%BE%8B-%E7%AE%80%E5%8D%95%E7%89%88/" class="title">IDEA数据清洗ETL实操案例-简单版</a>
              </p>
              <p class="item-date">
                <time datetime="2020-05-24T15:08:56.000Z" itemprop="datePublished">2020-05-24</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-尚硅谷hadoop笔记" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      尚硅谷hadoop笔记
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/" class="article-date">
	  <time datetime="2020-05-01T15:42:32.000Z" itemprop="datePublished">2020-05-01</time>
	</a>
</span>
        
        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">学习笔记</a>
  </span>


        
	<span class="article-read hidden-xs">
	    <i class="icon icon-eye-fill" aria-hidden="true"></i>
	    <span id="busuanzi_container_page_pv">
			<span id="busuanzi_value_page_pv">0</span>
		</span>
	</span>


        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h3 id="Hadoop概述："><a href="#Hadoop概述：" class="headerlink" title="Hadoop概述："></a>Hadoop概述：</h3><p>Hadoop: Apache基金会的分布式基础架构<br>解决<strong>海量数据存储</strong> 和 <strong>分析计算</strong> 问题</p>
<p>MySQL处理极限数据量在百万级别数据查询，大概1TB量<br>Hadoop:存：HDFS; 算：MapReduce</p>
<p>hadoop的组成：<br>1.x:<br>MapReduce:  计算 + 资源调度<br>HDFS: 数据存储</p>
<p>2.x:  解耦，实现计算模块可插拔<br>MapReduce: 计算<br>Yarn: 资源调度<br>HDFS：数据存储</p>
<h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>1)NameNode(nn)：目录索引，整个系统只有一份<br>存储文件的元数据，如文件名，文件目录结构，文件属性，以及每个文件的块列表和块所在的DataNode等</p>
<p>2)DataNode(dn)：移动硬盘们<br>在本地文件系统存储文件块数据，以及块数据校验和</p>
<p>3)Secondary NameNode(2nn)：是nn的助手，<strong>不是单纯的热备！！</strong>一般和nn不在一个节点上。<br>用来监控HDFS状态的辅助后台程序<br>目的是帮助nn合并编辑日志，减少nn的启动时间</p>
<h4 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h4><p>1)ResourceManager(RM)： 集群中只有一个，代表所有资源，组长<br>（1）处理客户端请求job submission<br>（2）监控NodeManager<br>（3）启动或监控ApplicationMaster<br>（4）资源分配与调度</p>
<p>2)NodeManager(NM):  组员<br>（1）管理单个节点上的资源<br>（2）处理来自ResourceManager的命令<br>（3）处理来自ApplicationMaster的命令</p>
<p>3)ApplicationMaster(AM):  临时负责人，不是常驻进程，有一个job就有一个AM<br>（1）负责数据切分<br>（2）为应用程序申请资源并分配给内部的任务<br>（3）任务的监控与容错</p>
<p>4)Container:  运行所有任务的容器，NM通过生成/关闭容器来调配资源，是资源分配的单元，不是常驻进程<br>  Yarn中资源的抽象，封装某节点多维度资源，如内存、CPU、磁盘、网络等</p>
<p><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/Yarn架构.png" alt></p>
<h4 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h4><p>分为两个阶段：Map阶段并行处理输入数据；Reduce阶段对Map结果进行汇总<br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce大概意思.png" alt></p>
<h4 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h4><p><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/大数据技术生态体系.png" alt></p>
<hr>
<h3 id="搭集群"><a href="#搭集群" class="headerlink" title="搭集群"></a>搭集群</h3><h4 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h4><p>快照类似游戏存档<br>快照一定要关机时候拍快照，这样只能保存硬盘的状态。<br>一般不照开机时的快照，因为会保存内存的内容，保存的内容很大，很占空间，而且没法由此克隆虚拟机。</p>
<hr>
<h3 id="卸载JDK命令"><a href="#卸载JDK命令" class="headerlink" title="卸载JDK命令"></a>卸载JDK命令</h3><p><code>rpm -qa | grep java | xargs sudo rpm -e --nodeps</code></p>
<h3 id="hadoop目录注意"><a href="#hadoop目录注意" class="headerlink" title="hadoop目录注意"></a>hadoop目录注意</h3><p><code>share文件夹：</code>hadoop 全部内容、本体基本都放在hadoop目录下的share文件夹，hadoop的jar包基本上也都放在share文件夹。<br><code>lib文件夹：</code>而hadoop目录下的lib文件夹中有个native文件夹，存放的是本地库文件，用于hadoop编译，运行时依赖于这些本地库，速度更快。找不到时才会使用java的内建版本，但运行慢。</p>
<hr>
<h3 id="编写集群分发脚本xsync"><a href="#编写集群分发脚本xsync" class="headerlink" title="编写集群分发脚本xsync"></a>编写集群分发脚本xsync</h3><h4 id="rsync-远程同步工具"><a href="#rsync-远程同步工具" class="headerlink" title="rsync 远程同步工具"></a>rsync 远程同步工具</h4><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。<br>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。<br>（1）基本语法<br>rsync    -arvl       $pdir/$fname              $user@hadoop$host:$pdir/$fname<br>命令   选项参数   要拷贝的文件路径/名称    目的用户@主机:目的路径/名称</p>
<p>选项参数说明<br>选项    功能<br>-r        递归<br>-a        归档复制<br>-v        显示复制过程<br>-l        拷贝符号连接</p>
<p>（2）案例实操<br>（a）把hadoop100机器上的/opt/software目录同步到hadoop101服务器的root用户下的/opt/目录<br><code>[hadoop@hadoop100 opt]$ rsync -arvl /opt/software/ root@hadoop101:/opt/software</code></p>
<h4 id="xsync集群分发脚本"><a href="#xsync集群分发脚本" class="headerlink" title="xsync集群分发脚本"></a>xsync集群分发脚本</h4><p>（1）需求：循环复制文件到所有节点的相同目录下</p>
<p>（2）需求分析：<br>（a）rsync命令原始拷贝：<br>rsync  -arvl     /opt/module   root@hadoop102:/opt/<br>（b）期望脚本：<br>xsync要同步的文件名称</p>
<font color="red">（c）说明：在/home/hadoop/bin这个目录下存放的脚本，hadoop用户可以在系统任何地方直接执行。</font>

<p>（3）脚本实现<br>（a）在/home/hadoop目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop101 ~]$ mkdir bin</span><br><span class="line">[hadoop@hadoop101 ~]$ cd bin/</span><br><span class="line">[hadoop@hadoop101 bin]$ touch xsync</span><br><span class="line">[hadoop@hadoop101 bin]$ vi xsync</span><br></pre></td></tr></table></figure><br>在该文件中编写如下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#1 获取输入参数个数，如果没有参数，直接退出</span><br><span class="line">pcount=$#</span><br><span class="line">if((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#2 获取文件名称</span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line">echo fname=$fname</span><br><span class="line"></span><br><span class="line">#3 获取上级目录到绝对路径</span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo pdir=$pdir</span><br><span class="line"></span><br><span class="line">#4 获取当前用户名称</span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line">#5 循环</span><br><span class="line">for((host=101; host&lt;109; host++)); do</span><br><span class="line">        echo ------------------- hadoop$host --------------</span><br><span class="line">        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure><br>（b）修改脚本 xsync 具有执行权限<br>[hadoop@hadoop101 bin]$ chmod 777 xsync<br>（c）调用脚本形式：xsync 文件名称<br>[hadoop@hadoop101 bin]$ xsync /home/hadoop/bin</p>
<font color="red">注意：如果将xsync放到/home/hadoop/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。</font>


<hr>
<h3 id="hadoop-运行模式"><a href="#hadoop-运行模式" class="headerlink" title="hadoop 运行模式"></a>hadoop 运行模式</h3><p>本地模式(Standalone Operation)：用于debug,测试用<br>伪分布式(Pseudo-Distributed Operation):只有一个节点的分布式</p>
<p>完全分布式(Fully-Distributed Operation):有多个节点的分布式，实际开发的环境，<strong>以下内容全为完全分布式配置：</strong></p>
<p><strong>集群部署规划如下所示：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop101:NN,DN,NM</span><br><span class="line">hadoop102:DN,RM,DM</span><br><span class="line">hadoop103:DN,NM,2NN,JobHistoryServer</span><br></pre></td></tr></table></figure><br><strong>须修改的配置文件如下：</strong><code>3个.sh</code> 、<code>4 个.xml</code> 、<code>1个slaves文件</code><br>core-site.xml:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hdfs://hadoop101:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><br>hadoop-env.sh:<br><code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code><br>hdfs-site.xml:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hadoop103:50090&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><br>yarn-env.sh:<br><code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code><br>yarn-site.xml:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Reducer获取数据的方式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop102&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><br>mapred-env.sh:<br><code>export JAVA_HOME=/opt/module/jdk1.8.0_144</code><br>mapred-site.xml:<br>首先复制mapred-site.xml.template为mapred-site.xml<br><code>cp mapred-site.xml.template mapred-site.xml</code><br>然后<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定MR运行在Yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>完全分布式下  启动和关闭  hdfs和yarn服务：</strong><br>首先：<br>若集群是第一次启动，需要格式化NN<br>在hadoop101上，执行<code>hadoop namenode -format</code><br>其次：<br>NN(hadoop101):起：<code>start-dfs.sh</code> 关：<code>stop-dfs.sh</code><br>RM(hadoop102):起：<code>start-yarn.sh</code> 关：<code>stop-yarn.sh</code></p>
<p><strong>完全分布式下执行wordcount程序：</strong><br>首先：在<code>wcinput目录下</code>下新建<code>wc.input</code>文件,其中写入需要统计单词的文本，并上传至集群中<br><code>mkdir wcinput</code><br><code>cd wcinput</code><br><code>vim wc.input</code><br><code>hadoop fs -put wcinput /</code><br>其次：运行<br><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /wcinput /output</code>(输出文件夹一定要不存在)<br>最后：查看输出结果<br><code>hadoop fs -cat /output/part-r-00000</code></p>
<hr>
<h3 id="免密登录ssh"><a href="#免密登录ssh" class="headerlink" title="免密登录ssh"></a>免密登录ssh</h3><p>免密登录原理：非对称加密rsa算法，公钥加密，私钥解密。<br>首先：在hadoop101上：<br>（1）生成公钥和私钥：<br><code>ssh-keygen -t rsa</code><br>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）<br>（2）将公钥拷贝到要免密登录的目标机器上<br><code>ssh-copy-id hadoop101</code><br><code>ssh-copy-id hadoop102</code><br><code>ssh-copy-id hadoop103</code></p>
<p>其次：在haoop102和hadoop103上也执行上述操作<br>或者在学习过程中，用集群分发脚本直接复制分发.ssh文件<br><code>xsync ~/.ssh</code><br>！！但不能在开发和工作环境中执行此操作，会破坏安全性！！</p>
<p>另：ssh文件夹下（~/.ssh）的文件功能解释<br><code>known_hosts</code>记录ssh访问过计算机的公钥(public key)<br><code>id_rsa</code>生成的私钥<br><code>id_rsa.pub</code>生成的公钥<br><code>authorized_keys</code>存放授权过得无密登录服务器公钥</p>
<h4 id="etc-profile-和-etc-bashrc的区别"><a href="#etc-profile-和-etc-bashrc的区别" class="headerlink" title="/etc/profile 和/etc/bashrc的区别"></a>/etc/profile 和/etc/bashrc的区别</h4><p><a href="https://www.cnblogs.com/yuanqiangfei/p/10232148.html" target="_blank" rel="noopener">linux中bashrc与profile的区别</a></p>
<hr>
<h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><h4 id="（1）配置slaves文件"><a href="#（1）配置slaves文件" class="headerlink" title="（1）配置slaves文件"></a>（1）配置slaves文件</h4><p>hadoop101的slaves:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop101</span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br></pre></td></tr></table></figure></p>
<font color="red">注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</font>

<p>同步所有节点配置文件<br><code>[hadoop@hadoop101 hadoop]$ xsync slaves</code></p>
<h4 id="（2）启动集群"><a href="#（2）启动集群" class="headerlink" title="（2）启动集群"></a>（2）启动集群</h4><ol>
<li>如果集群是第一次启动，需要格式化NameNode<font color="red">（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</font></li>
</ol>
<p><code>[hadoop@hadoop101 hadoop-2.7.2]$ bin/hdfs namenode -format</code></p>
<ol>
<li>启动HDFS<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop101 hadoop-2.7.2]$ sbin/start-dfs.sh</span><br><span class="line">[hadoop@hadoop101 hadoop-2.7.2]$ jps</span><br><span class="line">4166 NameNode</span><br><span class="line">4482 Jps</span><br><span class="line">4263 DataNode</span><br><span class="line">[hadoop@hadoop102 hadoop-2.7.2]$ jps</span><br><span class="line">3218 DataNode</span><br><span class="line">3288 Jps</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop103 hadoop-2.7.2]$ jps</span><br><span class="line">3221 DataNode</span><br><span class="line">3283 SecondaryNameNode</span><br><span class="line">3364 Jps</span><br></pre></td></tr></table></figure></li>
<li><p>启动YARN<br><code>[hadoop@hadoop102 hadoop-2.7.2]$ sbin/start-yarn.sh</code></p>
<font color="red">注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</font>
</li>
<li><p>Web端查看SecondaryNameNode<br>（a）浏览器中输入：<a href="http://hadoop103:50090/status.html" target="_blank" rel="noopener">http://hadoop103:50090/status.html</a><br>（b）查看SecondaryNameNode信息</p>
</li>
</ol>
<h4 id="（3）各个服务组件逐一启动-停止"><a href="#（3）各个服务组件逐一启动-停止" class="headerlink" title="（3）各个服务组件逐一启动/停止"></a>（3）各个服务组件逐一启动/停止</h4><p>分别启动/停止HDFS组件<br><code>hadoop-daemon.sh  start / stop  namenode / datanode / secondarynamenode</code><br>启动/停止YARN<br><code>yarn-daemon.sh  start / stop  resourcemanager / nodemanager</code></p>
<p>各个模块分开启动/停止（配置ssh是前提）常用<br>整体启动/停止HDFS<br><code>start-dfs.sh   /  stop-dfs.sh</code><br>整体启动/停止YARN<br><code>start-yarn.sh  /  stop-yarn.sh</code></p>
<hr>
<h3 id="配置历史服务器和日志聚集功能"><a href="#配置历史服务器和日志聚集功能" class="headerlink" title="配置历史服务器和日志聚集功能"></a>配置历史服务器和日志聚集功能</h3><p>mapred-site.xml:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 历史服务器端地址 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop103:10020&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 历史服务器web端地址 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop103:19888&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<p>yarn-site.xml:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 日志聚集功能使能 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	</span><br><span class="line">&lt;!-- 日志保留时间设置7天 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br></pre></td></tr></table></figure><br>启动日志服务器命令：<br>在日志服务器端(hadoop103)<br><code>mr-jobhistory-daemon.sh start historyserver</code><br>关闭日志服务器命令：<br><code>mr-jobhistory-daemon.sh stop historyserver</code></p>
<p><strong>“出错不要慌张，先冷静，然后去log目录下看.log文件定位错误！”</strong><br><strong>“读日志是一项很重要的技能！”</strong></p>
<hr>
<h3 id="时间同步服务"><a href="#时间同步服务" class="headerlink" title="时间同步服务"></a>时间同步服务</h3><h4 id="时间服务器配置（hadoop101、必须root用户）"><a href="#时间服务器配置（hadoop101、必须root用户）" class="headerlink" title="时间服务器配置（hadoop101、必须root用户）"></a>时间服务器配置（hadoop101、必须root用户）</h4><p>（1）检查ntp是否安装(使用root用户)<br><code>rpm -qa | grep ntp</code><br>出现<code>ntp-4.2.6p5-10.el6.centos.x86_64</code> 和 <code>ntpdate-4.2.6p5-10.el6.centos.x86_64</code>类似文件就证明已安装</p>
<p>（2）检查ntp运行状态<br><code>service ntp status</code><br>若正在运行则停止：<code>service ntp stop</code><br>取消服务自启动：<code>chkconfig ntpd off</code><br>查看服务状态：<code>chkconfig --list ntpd</code><br>上面两条在centos7.x以后分别是：<br><code>systemctl disable ntpd.service</code><br><code>systemctl status ntpd.service</code></p>
<p>（3）修改有关的配置文件<br>首先进入/etc/ntp.config文件：<br><code>sudo vim /etc/ntp.conf</code><br>a）修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为</span><br><span class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span><br></pre></td></tr></table></figure><br>b）修改2（集群在局域网中，不使用其他互联网上的时间）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst为</span><br><span class="line">#server 0.centos.pool.ntp.org iburst</span><br><span class="line">#server 1.centos.pool.ntp.org iburst</span><br><span class="line">#server 2.centos.pool.ntp.org iburst</span><br><span class="line">#server 3.centos.pool.ntp.org iburst</span><br></pre></td></tr></table></figure><br>c）添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）<br>server 127.127.1.0<br>fudge 127.127.1.0 stratum 10</p>
<p>其次进入/etc/sysconfig/ntpd文件：<br><code>sudo vim /etc/sysconfig/ntpd</code><br>增加内容如下（让硬件时间与系统时间一起同步）<br>SYNC_HWCLOCK=yes</p>
<p>（4）重启ntpd服务<br><code>systemctl start ntpd.service</code><br><code>systemctl status ntpd.service</code></p>
<p>（5）设置ntpd服务开机启动<br><code>systemctl enable ntpd.service</code></p>
<h4 id="其他机器配置（hadoop102和hadoop103、必须root用户）"><a href="#其他机器配置（hadoop102和hadoop103、必须root用户）" class="headerlink" title="其他机器配置（hadoop102和hadoop103、必须root用户）"></a>其他机器配置（hadoop102和hadoop103、必须root用户）</h4><p>（1）在其他机器配置10分钟与时间服务器同步一次<br><code>crontab -e</code><br>编写定时任务如下：<br><code>*/10 * * * * /usr/sbin/ntpdate hadoop102</code><br>（2）修改任意机器时间<br><code>date -s &quot;2017-9-11 11:11:11&quot;</code><br>（3）十分钟后查看机器是否与时间服务器同步<br><code>date</code><br>说明：测试的时候可以将10分钟调整为1分钟，节省时间。</p>
<hr>
<h3 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h3><p>Hadoop Distributed File System<br>HDFS的使用场景：适合一次写入、多次读出的场景，且不支持文件的修改</p>
<h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>优点：高容错性(可恢复的多副本)、适合处理大数据(PB级别数据量、百万规模文件数量)、可构建在廉价机器上(和超算相比，后者就是硬件牛逼)</p>
<p>缺点：不适合低延时数据访问(运行慢)、无法高效对大量小文件进行存储(NN的条目太多)、不支持<strong>并发写入</strong>和文件随机修改(单线程写，仅支持数据追加append，修改只能删除重写)</p>
<h4 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h4><p>1）NameNode(nn):Master,主管、管理者<br>    (1)管理HDFS的名称空间<br>    (2)配置副本策略<br>    (3)管理数据块(Block)映射信息<br>    (4)处理客户端读写请求</p>
<p>2）DataNode(dn):slave,nn下达命令，dn执行实际的操作<br>    (1)存储实际的数据块<br>    (2)执行数据块的读/写操作</p>
<p>3）Client:客户端<br>    (1)文件切分。将文件切分为block，再上传<br>    (2)与nn交互，获取文件位置<br>    (3)与dn交互，读写数据<br>    (4)提供命令管理HDFS，如nn格式化<br>    (5)通过命令访问HDFS，如对HDFS进行CRUD</p>
<p>4）Secondary NameNode(2nn):不是nn的热备。不能在nn挂掉时，立刻替换<br>    (1)辅助nn，分担工作量</p>
<h4 id="HDFS文件块大小（面试重点）"><a href="#HDFS文件块大小（面试重点）" class="headerlink" title="HDFS文件块大小（面试重点）"></a>HDFS文件块大小（面试重点）</h4><p>块的大小可通过配置参数(dfs.blocksize)来规定</p>
<font color="red">默认大小在Hadoop2.x版本中是128M，老版本是64M</font>

<p><strong>原因：</strong><br>块平均寻址时间为10ms</p>
<font color="red">寻址时间为传输时间的1%时，则为最佳状态</font>

<p>因此传输时间为：<br>10ms/0.01=1000ms=1s<br>而目前磁盘的传输速率普遍为100MB/s<br>所以取2的幂：128M</p>
<p><strong>块不能设置太小，也不能设置太大！</strong><br>太小：增加寻址时间，很慢<br>太大：会导致MapReduce处理不方便，很慢</p>
<hr>
<h4 id="HDFS的Shell操作-开发重点"><a href="#HDFS的Shell操作-开发重点" class="headerlink" title="HDFS的Shell操作(开发重点)"></a>HDFS的Shell操作(开发重点)</h4><p><code>hadoop fs</code> 和 <code>hdfs dfs</code>的效果一模一样，因为源码中调用的是同一个.sh文件</p>
<p><strong>Hadoop fs 命令分类：</strong></p>
<p>本地——》HDFS<br>    put<br>    copyFromLocal(和put功能一模一样，只是为了兼容以前的命令)<br>查看命令帮助：<code>hadoop fs -copyFromLocal -help</code><br>    moveFromLocal(上面复制，这个是剪切)<br>    appendToFile</p>
<p>HDFS——》HDFS<br>    cp<br>    mv<br>    chown<br>    chgrp<br>    chmod<br>    mkdir<br>    du<br>    df<br>    cat<br>    rm<br>    setrep(注：任何情况下，副本数都不可能比dn结点数多。一个dn至多只能存同一个数据的一份副本)</p>
<p>HDFS——》本地<br>    get<br>    getmerge：合并下载成一个文件<br>    copyToLocal(和get功能一模一样，兼容以前的命令)</p>
<p>小技巧：<a href="https://www.cnblogs.com/zhongjianlong/archive/2013/09/17/linux.html" target="_blank" rel="noopener">cat &lt;&lt; EOF &gt;&gt;1.txt创建文件</a></p>
<hr>
<h3 id="IDEA环境设置"><a href="#IDEA环境设置" class="headerlink" title="IDEA环境设置"></a>IDEA环境设置</h3><p><a href="https://blog.csdn.net/qq_39929929/article/details/103753905" target="_blank" rel="noopener">在Intelij IDEA中修改maven源为国内（阿里）镜像</a></p>
<h3 id="Maven简要介绍"><a href="#Maven简要介绍" class="headerlink" title="Maven简要介绍"></a>Maven简要介绍</h3><p><strong>Maven是用来管理项目的工具</strong><br><a href="https://www.bilibili.com/video/BV164411Z7cR?p=24" target="_blank" rel="noopener">B站Mvn回顾</a></p>
<p>有一个专门搜Maven依赖的网站<br><a href="https://mvnrepository.com/" target="_blank" rel="noopener">MVNRepository</a></p>
<hr>
<h3 id="HDFS客户端开发（IDEA）"><a href="#HDFS客户端开发（IDEA）" class="headerlink" title="HDFS客户端开发（IDEA）"></a>HDFS客户端开发（IDEA）</h3><p>HDFS的Shell和客户端是开发的重点，须多加练习<br><strong>客户端操作本质上就是封装了shell语句的java程序，实现和逻辑都是shell</strong><br><a href="/2020/05/15/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BB%83%E4%B9%A0/" title="HDFS客户端练习">HDFS客户端练习</a></p>
<hr>
<h3 id="HDFS的数据流（面试重点）"><a href="#HDFS的数据流（面试重点）" class="headerlink" title="HDFS的数据流（面试重点）"></a>HDFS的数据流（面试重点）</h3><h4 id="HDFS上传流程"><a href="#HDFS上传流程" class="headerlink" title="HDFS上传流程"></a>HDFS上传流程</h4><p>首先获得HDFS抽象封装，开启本地文件输入流和FSDataOutputStream输出流，然后：<br>    1.client向NN请求上传请求<br>    2.NN返回给client应答是否上传结果<br>    3.获得许可后，client逻辑切分文件为多个block<br>    4.client向NN请求上传第一个block<br>    5.NN给client返回多个DN(最近节点和其他节点)<br>    6.client依次向所有DN发送请求建立通道<br>    7.DN依次判断后向client返回应答成功<br>    8.client依次向所有DN以 packet(64KB) 形式上传数据，直到发送成功第一个block，并存储在DN中。这里传输会出现多种情况，具体可看视频。<br>    9.依次类推，直到发送完毕所有block<br>最后，上传文件结束，释放文件输入流和FSDataOutputStream输出流<br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/HDFS上传流程.png" alt></p>
<p><strong>具体上传过程可看：</strong><br><a href="https://www.bilibili.com/video/BV164411Z7cR?p=21" target="_blank" rel="noopener">B站详细HDFS上传流程 01:38开始</a></p>
<h4 id="拓扑距离-最近节点-和机架感知-其他节点"><a href="#拓扑距离-最近节点-和机架感知-其他节点" class="headerlink" title="拓扑距离(最近节点)和机架感知(其他节点)"></a>拓扑距离(最近节点)和机架感知(其他节点)</h4><p><a href="https://www.bilibili.com/video/BV164411Z7cR?p=23" target="_blank" rel="noopener">B站详细讲解</a></p>
<h4 id="HDFS下载流程"><a href="#HDFS下载流程" class="headerlink" title="HDFS下载流程"></a>HDFS下载流程</h4><p>首先获得HDFS抽线封装，开启本地文件输出流和FSDataInputStream输入流，然后：<br>    1.client向NN请求下载请求<br>    2.NN返回给client应答文件是否存在<br>    3.获得许可后，client请求下载第一个block(0-128M)<br>    4.NN返回给client返回多个DN<br>    5.client首先向第1个DN请求建立通道<br>    6.DN1判断并向client返回应答成功，并传输packet数据，直到传输成功第1个block<br>    7.如果第一个DN应答失败才会向其他DN请求建立通道，每次请求一个DN，进行接下来的操作<br>    8.以此类推，接收完所有block<br>最后，下载文件结束，释放文件输出流和FSDataInputStream输入流<br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/HDFS下载流程.png" alt></p>
<p><strong>具体下载过程可看：</strong><br><a href="https://www.bilibili.com/video/BV164411Z7cR?p=22" target="_blank" rel="noopener">B站详细HDFS下载流程</a></p>
<hr>
<h4 id="NN和2NN工作机制-面试开发重点"><a href="#NN和2NN工作机制-面试开发重点" class="headerlink" title="NN和2NN工作机制(面试开发重点)"></a>NN和2NN工作机制(面试开发重点)</h4><p><strong>需要应对内存中的数据的持久化问题</strong><br>NameNode的内存大小一般在64G到128G之间</p>
<p>如此大块数据的持久化，有样例：Redis的持久化，有两个策略：<br>RDB：内存镜像放在磁盘上，类似存档；<br>    特点：    持久化慢，占空间偏小；<br>            （加载高效，生成较慢）<br>            安全性低；</p>
<p>AOF：命令操作流程记录在AOF文件中，类似命令小纸条<br>    特点：持久化快，占空间偏大；<br>            （加载慢，生成较快）<br>            安全性高；</p>
<h4 id="NN和2NN关系类比-老板和秘书"><a href="#NN和2NN关系类比-老板和秘书" class="headerlink" title="NN和2NN关系类比(老板和秘书)"></a>NN和2NN关系类比(老板和秘书)</h4><p>NN和Redis策略相似，有Fsimage(类RDB)和edits.log(类AOF)<br>Fsimage类似旧存档，edits.log类似旧存档之后还没保存的操作<br>2NN定期将Fsimage和edits.log整合成一个新的存档Fsimage_chkpoint，返回给NN恢复内存状态<br>    定期(条件满足一个即可)：<br>        1.定时，通常每隔1小时2NN执行一次<br>        2.edits满，通常1分钟2NN检查一次，当操作次数达到1百万时，2NN执行一次<br>        3.NN刚启动时2NN也会执行一次<br><a href="https://www.bilibili.com/video/BV164411Z7cR?p=25" target="_blank" rel="noopener">B站详细讲解NN和2NN 从25:23开始</a></p>
<h4 id="Fsimage和Edits解析"><a href="#Fsimage和Edits解析" class="headerlink" title="Fsimage和Edits解析"></a>Fsimage和Edits解析</h4><p>Fsimage和Edits文件在<code>/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current/</code><br>Fsimage只保留一个最新的和第二新的，Edits都保留</p>
<p>查看Fsimage命令：<code>hdfs oiv -p XML -i fsimage_xxx -o /opt/module/hadoop/fsimage.xml</code><br>查看Edits命令：<code>hdfs oev -p XML -i edits_xxx -o /opt/module/hadoop/edits.xml</code></p>
<p>可以再使用<code>sz命令</code>拷贝到宿主机win10上查看</p>
<hr>
<h3 id="DN工作机制-面试开发重点"><a href="#DN工作机制-面试开发重点" class="headerlink" title="DN工作机制(面试开发重点)"></a>DN工作机制(面试开发重点)</h3><p>DN上的块在<code>/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current/</code><br>其中不仅有块数据，还有块对应元数据meta文件(数据长度、校验和、时间戳)</p>
<p>1.DN向NN注册<br>2.DN注册成功<br>3.DN除在最开始，而且每周期(1h)上报所有块信息<br>4.每3秒一次心跳(last contact)，心跳返回的结果带有NN给DN的命令<br>5.默认超过(10分钟+30秒)没有DN的心跳，则认为该节点不可用</p>
<p><strong>掉线时限参数设置：</strong><br><code>TimeOut = 2 * dfs.namenode.heartbeat.recheck-interval(5min) + 10 * dfs.heartbeat.interval(3s)</code><br>可以修改上面两个参数</p>
<p><strong>数据校验算法：</strong>保证数据完整性<br>    crc(散列值：32bit)：HDFS传输一般数据<br>    md5(128bit)：HDFS传输元数据<br>    sha1(160bit)：安全性高，算一次消耗cpu多，传输代价高<br><a href="https://www.bilibili.com/video/BV164411Z7cR?p=26" target="_blank" rel="noopener">B站详解DN</a></p>
<h4 id="服役新节点、退役旧节点、多目录配置"><a href="#服役新节点、退役旧节点、多目录配置" class="headerlink" title="服役新节点、退役旧节点、多目录配置"></a>服役新节点、退役旧节点、多目录配置</h4><p><strong>服役新节点比较简单，之前从伪分布式到完全分布式时已经做过，只须做到以下几点，新节点就能接入集群：</strong><br>1.环境准备，如jdk和hadoop环境。<code>rsync</code>一下hadoop有关的配置文件<br>2.更改ip和主机名，保证在</p>
<font color="red">3.删除原来HDFS保留的data和log文件夹</font>

<p>4.source一下配置文件：<code>source /etc/profile</code><br>5.单点启动DN时:<code>hadoop-daemon.sh start datanode</code>和<code>yarn-daemon.sh start nodemanager</code>,如果遇到数据不均衡，还可以使用<code>start-balancer.sh</code>命令实现集群的再平衡</p>
<p><strong>退役旧节点有两种策略：添加白名单、黑名单退役。</strong><br><strong>HDFS使用的一般是黑名单。设置都在NN所在主机操作</strong><br>白名单机制一般是保证集群准入机制，保证集群自身的安全性，不多用于退役节点。</p>
<p>黑名单机制比较温和，主要是添加<code>hdfs-site.xml</code>中<code>dfs.hosts.exclude</code>属性与值：<br>1.创建黑名单文件<code>blacklist</code>,写入要退役的主机名<br>2.在<code>hdfs-site.xml</code>中添加<code>dfs.hosts.exclude</code>属性，值就是黑名单文件<code>blacklist</code>的地址<br>3.刷新NameNode、刷新ResourceManager<br><code>hdfs dfsadmin -refreshNodes</code><br><code>yarn rmadmin -refreshNodes</code><br>4.检查web浏览器，退役节点状态显示为<code>decommission in progress(退役中)</code>，过会儿显示为<code>decommissioned(所有块复制完成，退役结束)</code>,但此时心跳仍然存在，只是集群不存放和处理这个节点的数据。如要完全退出就单点退出hdfs和yarn<br>5.遇到数据不均匀，还可以使用<code>start-balancer.sh</code>命令实现集群再平衡</p>
<p>白名单机制比较激进，主要是添加<code>hdfs-site.xml</code>中<code>dfs.host</code>属性与值<br>1.创建白名单文件<code>whitelist</code>，写入可以进入集群的主机名<br>2.在<code>hdfs-site.xml</code>中添加<code>dfs.hosts</code>属性，值就是白名单<code>whitelist</code>的地址<br>3.配置文件分发到所有节点：<code>xsync hdfs-site.xml</code><br>4.刷新NameNode、刷新ResourceManager<br><code>hdfs dfsadmin -refreshNodes</code><br><code>yarn rmadmin -refreshNodes</code><br>5.在web浏览器查看当前DN节点情况<br>6.遇到数据不均匀，还可以使用<code>start-balancer.sh</code>命令实现集群再平衡</p>
<p><strong>多目录配置主要是为了解决数据增大，硬盘容量不足的问题</strong><br>DataNode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本</p>
<p>具体配置在<code>hdfs-site.xml</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/data1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/data2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><br>data2文件夹类似于在该挂载点处多挂载了一块新的硬盘</p>
<hr>
<h3 id="MapReduce简述与序列化"><a href="#MapReduce简述与序列化" class="headerlink" title="MapReduce简述与序列化"></a>MapReduce简述与序列化</h3><p>优点：简单；缺点：慢<br>一个完整的MapReduce程序在分布式运行时有三类实例进程：<br>1.<strong>MrAppMaster</strong>:负责整个程序的过程调度及状态协调<br>2.<strong>MapTask</strong>:负责Map阶段整个数据处理流程（映射）<br>3.<strong>ReduceTask</strong>:负责Reduce阶段整个数据处理流程(合并规约)</p>
<h4 id="常用数据序列化类型"><a href="#常用数据序列化类型" class="headerlink" title="常用数据序列化类型"></a>常用数据序列化类型</h4><p>Java类型    Hadoop Writable类型<br>boolean        BooleanWritable<br>byte        ByteWritable<br>int            IntWritable<br>float        FloatWritable<br>long        LongWritable<br>double        DoubleWritable<br><strong>String        Text</strong><br>map            MapWritable<br>array        ArrayWritable</p>
<h4 id="动手在IDEA上写一个MapReduce程序实现WordCount"><a href="#动手在IDEA上写一个MapReduce程序实现WordCount" class="headerlink" title="动手在IDEA上写一个MapReduce程序实现WordCount"></a>动手在IDEA上写一个MapReduce程序实现WordCount</h4><a href="/2020/05/18/IDEA%E6%89%8B%E5%86%99%E7%A4%BA%E4%BE%8B%E7%A8%8B%E5%BA%8Fwordcount%E5%B9%B6%E6%89%93%E5%8C%85%E8%BF%90%E8%A1%8C/" title="IDEA手写示例程序wordcount并打包运行">IDEA手写示例程序wordcount并打包运行</a>
<h4 id="自定义序列化接口"><a href="#自定义序列化接口" class="headerlink" title="自定义序列化接口"></a>自定义序列化接口</h4><a href="/2020/05/18/IDEA%E6%89%8B%E5%86%99%E8%87%AA%E5%AE%9A%E4%B9%89bean%E5%AF%B9%E8%B1%A1%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E5%8C%96%E6%8E%A5%E5%8F%A3Writable/" title="IDEA手写自定义bean对象实现序列化接口Writable">IDEA手写自定义bean对象实现序列化接口Writable</a>
<p>以上可知：<br>用户编写的程序分成三个部分：Mapper、Reducer和Driver。<br><strong>Mapper阶段：</strong><br>1.用户自定义Mapper要继承框架父类Mapper<br>2.Mapper的输入数据是KV对形式，类型可自定义<br>3.Mapper的业务逻辑写在map()方法中<br>4.Mapper的输出数据是KV对形式，类型可自定义<br>5.map()方法(MapTask进程)对每个&lt; K,V &gt;调用一次<br><strong>Reducer阶段：</strong><br>1.用户自定义Reducer要继承框架父类Reducer<br>2.Reducer的输入数据类型对应Mapper的输出数据类型，是KV对形式<br>3.Reducer的业务逻辑写在reduce()方法中<br>4.Reducer的输出数据是KV对形式，类型可自定义<br>5.ReduceTask进程对每组相同K的&lt; K,V &gt;调用一次reduce()方法<br><strong>Driver阶段：</strong><br>相当于YARN集群客户端，用于提交我们程序到YARN，提交是封装了MapReduce程序相关运行参数的job对象</p>
<hr>
<h3 id="MapReduce框架原理-非常重要"><a href="#MapReduce框架原理-非常重要" class="headerlink" title="MapReduce框架原理(非常重要)"></a>MapReduce框架原理(非常重要)</h3><h4 id="MapReduce的数据流"><a href="#MapReduce的数据流" class="headerlink" title="MapReduce的数据流"></a>MapReduce的数据流</h4><p><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce的数据流.png" alt></p>
<h4 id="数据切片与MapTask并行度决定机制，切片由InputFormat负责"><a href="#数据切片与MapTask并行度决定机制，切片由InputFormat负责" class="headerlink" title="数据切片与MapTask并行度决定机制，切片由InputFormat负责"></a>数据切片与MapTask并行度决定机制，切片由InputFormat负责</h4><p><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/数据切片与MapTask并行度决定机制.png" alt></p>
<h4 id="InputFormat数据输入"><a href="#InputFormat数据输入" class="headerlink" title="InputFormat数据输入"></a>InputFormat数据输入</h4><p>InputFormat主要只干两件事：<strong>切片</strong>、<strong>输出KV值</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Inputformat			切片方法			KV方法</span><br><span class="line">Text				FIF的切片方法		LineRecordReader</span><br><span class="line">KeyValue			FIF的切片方法		KeyValueLineRecordReader</span><br><span class="line">NLine				自定义，N行一片		LineRecordReader</span><br><span class="line">CombineText			自定义,跨小文件切分				CombineFileRecordReader</span><br><span class="line">FixedLength			FIF的切片方法		FixedLengthRecordReader</span><br><span class="line">SequenceFile		FIF的切片方法		SequenceFileRecordReader</span><br></pre></td></tr></table></figure><br><a href="/2020/05/19/IDEA%E8%87%AA%E5%AE%9A%E4%B9%89InputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA自定义InputFormat案例实操">IDEA自定义InputFormat案例实操</a></p>
<h4 id="Shuffle机制-非常重要"><a href="#Shuffle机制-非常重要" class="headerlink" title="Shuffle机制(非常重要)"></a>Shuffle机制(非常重要)</h4><ol>
<li><p>Map方法结束后，数据进入环形缓冲区。当环形缓冲区满时，数据溢写要落盘，落盘前，先得到一个逻辑分区号，然后需完成<font color="red">分区和排序</font>的工作,本质上是一个工作，二排序(先分区号，后按Key)完之后相同key相邻就完成了分区。<br>分区结束后，得到分区且区内有序文件，排序方法使用<strong>快排</strong>。<br>得到多个上述分区文件后，按照分区号，可进入Combiner进行一次分区的归并排序，减少之后IO的操作。<br>数据多次溢写文件，会多次输出文件。这些溢写文件再进行一次<strong>归并排序</strong>，进入Combiner之后落盘，得到按照分区且区内有序的文件。这就是一个MapTask的输出。</p>
</li>
<li><p>当有n个MapTask的输出文件时，启动和分区数m个相同的ReduceTask，并按分区号取出分区文件内容。每个ReduceTask都会处理所有n个MapTask相应分区的数据。最后在内存缓存中产生m个文件，内存缓存满了才会使用磁盘。<br>接着，在内存缓存中再进行<strong>归并</strong>合成一整个输出文件，特点是key有序或按照自定义规则排好序，之后分组，并输入到Reduce方法中。其中分组阶段可以使用自定义分组规则，但注意之前排序规则就要比分组规则写的更细。如分组是按订单分组，那排序则需要先按订单排序，订单内部再按其他规则排序，这样才不会出现逻辑问题。<br>最后将分组文件交给OutputFormat,再经过RecordWriter输出。其中，一个ReduceTask对应一个输出文件。<br>整个Shuffle过程有<strong>三次排序</strong>过程。<br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/Shuffle机制.png" alt></p>
</li>
<li><p>环形缓冲区本质上就是内存。环形最大特点是没头没尾，所以在哪里写入都一样。默认是100M大小。写入数据时，任意一点开始，右边写入KV值，左边同时写入KV值对应的位置索引Index。遍历时，遍历索引index，因为占内存小，遍历省时。<br>当写入占环形缓冲容量的80%左右时，会发生溢写过程。当溢写时，Map方法来的数据写入剩余20%部分。环形的设计还可保持处理和写入的动态平衡。<br>默认80%参数可调，如果Map方法逻辑复杂，参数可调小；如果任务IO剧烈，压力比较大，参数调大一些。总之保证写入和处理动态平衡。<br>其实溢写过程的分区和排序也就是发生在环形缓冲区中。排序时，实际上不交换KV值，是交换索引Index，好处是Index的IO交换代价小。</p>
</li>
</ol>
<p><strong>Partition分区案例实操</strong><br>ReduceTask的并行度是手动设置的，由job.setNumReduceTasks()方法决定。<br>分区是告诉数据应该被哪个ReduceTask处理。且分区号要从0开始，逐一累加，不能跳。<br>如果分区数量比ReduceTask的数量多，程序会报IOException:Illegal partition异常。<br>如果分区数量比ReduceTask的数量少，程序可正常运行，但是会有资源浪费，有ReduceTask空转，没有有效输出。<br><a href="/2020/05/20/IDEA%E6%89%8B%E5%86%99Partition%E5%88%86%E5%8C%BA%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA手写Partition分区案例实操">IDEA手写Partition分区案例实操</a></p>
<p><strong>WritableComparable排序</strong><br>排序是MapReduce框架中最重要的操作之一。<br>MapTask结束后，必然已经对得到的分区文件按key值排好序了。<br><a href="/2020/05/21/IDEA%E6%89%8B%E5%86%99WritableComparable%E6%8E%92%E5%BA%8F%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA手写WritableComparable排序案例实操">IDEA手写WritableComparable排序案例实操</a></p>
<p><strong>Combiner合并</strong><br>Conbiner的父类是Reducer。与Reducer的区别在于：<br>    Combiner是在每个MapTask所在的节点运行；<br>    Reducer是接收全局所有Mapper的输出结果。<br>Combiner启用的意义就是对每个MapTask的输出进行局部汇总，目的是减少IO</p>
<p>Combiner默认是不启动的，能够启用的前提是不能影响最终的业务逻辑。而且Combiner输入和输出的类型必须相同，因为不能改<br>变Mapper输出的类型。</p>
<p>Combiner对数据要求是数据本身可分组，是有序且有重复的。<br>故其在第一次排序——快排和第二次排序——归并起效。<br><a href="/2020/05/21/IDEA%E6%89%8B%E5%86%99Combiner%E5%90%88%E5%B9%B6%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA手写Combiner合并案例实操">IDEA手写Combiner合并案例实操</a></p>
<p><strong>GroupingComparator分组排序器，辅助排序</strong><br>何时分组：Reduce阶段，在之前排序阶段之后<br>何时启用GroupingComparator：<font color="red">分组规则和排序规则不一样时，不希望默认按照Key比较规则</font>。排序规则的粒度要更细，要体现出分组的规则。<br><a href="/2020/05/21/IDEA%E6%89%8B%E5%86%99GroupingComparator%E5%88%86%E7%BB%84%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA手写GroupingComparator分组案例实操">IDEA手写GroupingComparator分组案例实操</a></p>
<h4 id="reduce-方法输入原理"><a href="#reduce-方法输入原理" class="headerlink" title="reduce()方法输入原理"></a>reduce()方法输入原理</h4><p>Reduce输入端只有一个空键对象Key和一个空值对象Value，所有数据在框架中都是通过KV值序列化的流传递，通过反序列化不断更新复用对象，达到遍历所有对象的需求。<br>数据的输入和分组是同时完成的。因为数据量非常大时，使用序列化方法复用对象，可以避免重复产生大量对象消耗资源。并且，反序列化遍历对象时，每个ReduceTask会默认调用Reduce方法，输出排序后每组第一个key所对应的对象(context.write(key,value.get()))。<br>如果想要取每组若干名，则可使用迭代器方法逐个在组内反序列化。详情可看<a href="/2020/05/21/IDEA%E6%89%8B%E5%86%99GroupingComparator%E5%88%86%E7%BB%84%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA手写GroupingComparator分组案例实操">IDEA手写GroupingComparator分组案例实操</a>中Reducer对象中reduce方法中的写法。</p>
<h4 id="MapReduce详细工作流程"><a href="#MapReduce详细工作流程" class="headerlink" title="MapReduce详细工作流程"></a>MapReduce详细工作流程</h4><p><strong>自己必须可以画出整个工作流程！</strong><br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce详细工作流程一.png" alt><br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce详细工作流程二.png" alt><br>详细过程细节理解还可以参考这个网站：<a href="https://www.cnblogs.com/52mm/p/p15.html" target="_blank" rel="noopener">MapReduce过程详解(基于hadoop2.x架构)</a></p>
<h4 id="自定义RecordWriter"><a href="#自定义RecordWriter" class="headerlink" title="自定义RecordWriter"></a>自定义RecordWriter</h4><p>FileInputFormat是文件到KV值<br>FileOutputFormat是KV值到文件<br><a href="/2020/05/23/IDEA%E8%87%AA%E5%AE%9A%E4%B9%89OutputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA自定义OutputFormat案例实操">IDEA自定义OutputFormat案例实操</a></p>
<h4 id="MapReduce应用"><a href="#MapReduce应用" class="headerlink" title="MapReduce应用"></a>MapReduce应用</h4><p><strong>ReduceJoin案例实操</strong><br>数据库中Join操作是连接两张表的操作，大致可分为内连接、外连接，左连接、右连接和自然连接。<br><a href="https://www.cnblogs.com/fudashi/p/7491039.html" target="_blank" rel="noopener">MySQL的JOIN(一):用法</a><br>ReduceJoin的含义是实际的Join工作是在Reduce端完成的，因为Reduce有数据汇总的步骤。<br>Map端为不同表或文件的KV值，打标签以区别不同来源的记录。然后用连接字段作为key,其余部分和新加的标志作为value,进行输出。<br>Reduce端将每个分组中来源于不同文件的记录分开，然后分别合并。</p>
<a href="/2020/05/24/IDEA%E6%89%8B%E5%86%99ReduceJoin%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA手写ReduceJoin案例实操">IDEA手写ReduceJoin案例实操</a>
<p><strong>MapJoin案例实操</strong><br>MapJoin的含义是实际的Join工作是在Map端完成的。<br>MapJoin适用于一张表十分小(或者几张小表，但是能全部进内存)、一张表很大的场景。<br>优点：在Map端就完成了join操作，所以就不需要Reduce端的工作，也不需要shuffle,也不会因为shuffle而引起数据倾斜。</p>
<a href="/2020/05/24/IDEA%E6%89%8B%E5%86%99MapJoin%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D/" title="IDEA手写MapJoin案例实操">IDEA手写MapJoin案例实操</a>
<p><strong>数据清洗ETL案例实操</strong><br>在运行核心业务MapReduce程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。清理的过程往往只需要运行Mapper程序，不需要运行Reduce程序。<br><a href="/2020/05/24/IDEA%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97ETL%E5%AE%9E%E6%93%8D%E6%A1%88%E4%BE%8B-%E7%AE%80%E5%8D%95%E7%89%88/" title="IDEA数据清洗ETL实操案例-简单版">IDEA数据清洗ETL实操案例-简单版</a><br><a href="/2020/05/24/IDEA%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97ETL%E5%AE%9E%E6%93%8D%E6%A1%88%E4%BE%8B-%E5%A4%8D%E6%9D%82%E7%89%88/" title="IDEA数据清洗ETL实操案例-复杂版">IDEA数据清洗ETL实操案例-复杂版</a></p>
<h4 id="MapReduce开发总结"><a href="#MapReduce开发总结" class="headerlink" title="MapReduce开发总结"></a>MapReduce开发总结</h4><p><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce开发总结1.png" alt><br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce开发总结2.png" alt><br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce开发总结3.png" alt><br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce开发总结4.png" alt><br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/MapReduce开发总结5.png" alt><br><strong>MapReduce的重点在Shuffle机制</strong></p>
<hr>
<h4 id="HDFS-HA高可用"><a href="#HDFS-HA高可用" class="headerlink" title="HDFS HA高可用"></a>HDFS HA高可用</h4><p>1.x版本存在单点故障(SPOF)<br>2.x版本实现了高可用(High Available),即7*24小时不中断服务<br>实现高可用最关键的策略是消除单点故障。HA严格应分为各个组件的HA机制：HDFS的HA 和 YARN的HA。</p>
<p>四大部分：<br>NN（active和standby）、第三方的edits文件管理系统QJM、ZK集群、Zk集群在NN上的客户端ZKfc<br>主要防止:split brain/脑裂 问题(两个NN导致的数据不安全问题)<br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/HDFS-HA故障转移机制.png" alt></p>
<p>内容过于细节，参考讲解文档，实现细节略有不同。</p>
<h4 id="YARN-HA高可用"><a href="#YARN-HA高可用" class="headerlink" title="YARN HA高可用"></a>YARN HA高可用</h4><p>YARN和HA都是2.x版本中的新特性，互相都在迭代过程中，所以很多东西已经设计在一起了。<br><img src="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/YARN-HA工作机制.png" alt></p>
<p>同样内容过于细节，参考详解文档，实现细节略有不同。</p>
<h4 id="HDFS-Federation架构设计"><a href="#HDFS-Federation架构设计" class="headerlink" title="HDFS Federation架构设计"></a>HDFS Federation架构设计</h4><p>主要解决由于DN数量增大，导致的NN内存不够的问题。<br>Federation的含义是：多个NN组成一个Block Pools,共同管理一片元数据，每个NN负责其中一个部分。</p>
<hr>
<h3 id="MapReduce扩展案例"><a href="#MapReduce扩展案例" class="headerlink" title="MapReduce扩展案例"></a>MapReduce扩展案例</h3><h4 id="TopN案例"><a href="#TopN案例" class="headerlink" title="TopN案例"></a>TopN案例</h4><p>本案例需求：<br>对 序列化操作案例 输出结果进行加工，输出流量使用量在前10的用户信息<br>解决思路：<br>将所有输出归总到同一个组中，只取前10个。所以要指定GroupComparator的compare分组方法。<br>实现细节与讲解文档略有不同。<br><a href="/2020/05/27/IDEA%E4%B8%8ATopN%E6%A1%88%E4%BE%8B/" title="IDEA上TopN案例">IDEA上TopN案例</a></p>
<h4 id="倒排索引案例"><a href="#倒排索引案例" class="headerlink" title="倒排索引案例"></a>倒排索引案例</h4><p>倒排索引是搜索引擎中非常重要的部分。<br>倒排的含义是：从 单词 到 文章 的索引。 正排：从文章到单词的索引<br>本案例需求：<br>对关键词出现的文档和该文档中出现的频率进行统计。<br>解决思路：<br>实际上是一个多job串联，每个job实现一个wordcount功能<br>第一次针对每个单词每篇文章做一次wordcount,key是单词-文章名，value是出现的次数；<br>第二次对结果文件进行处理，将key重新划分为单词，将value重新划分为文章名和对应出现次数的拼接字符串。<br>实现细节与讲解文档略有不同。<br></p>
<h4 id="找博客共同好友案例"><a href="#找博客共同好友案例" class="headerlink" title="找博客共同好友案例"></a>找博客共同好友案例</h4><p>共同好友的延申：推荐共同好友<br>本案例需求：<br>以下是博客的好友列表数据，冒号前是一个用户，冒号后是该用户的所有好友（数据中的好友关系是单向的）<br>求出哪些人两两之间有共同好友，及他俩的共同好友都有谁？<br>解决思路：<br>首先第一次输出先找出A、B、C等都被谁关注。转变视角从我关注了谁，到谁关注了我。<br>其次，再从输出文件中每行的value两两找出关注者。<br>实现细节与讲解文档略有不同。<br><a href="/2020/05/27/IDEA%E4%B8%8A%E6%89%BE%E5%8D%9A%E5%AE%A2%E5%85%B1%E5%90%8C%E5%A5%BD%E5%8F%8B%E6%A1%88%E4%BE%8B/" title="IDEA上找博客共同好友案例">IDEA上找博客共同好友案例</a></p>
<hr>
<h3 id="Hadoop重点"><a href="#Hadoop重点" class="headerlink" title="Hadoop重点"></a>Hadoop重点</h3><p>入门：Hadoop组成<br>HDFS:HDFS的shell操作、HDFS的数据流<br>MapReduce:Shuffle机制(出现数据倾斜)、YARN工作机制</p>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://www.fluffysponge.fun/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/" title="尚硅谷hadoop笔记" target="_blank" rel="external">https://www.fluffysponge.fun/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7hadoop%E7%AC%94%E8%AE%B0/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/InstantCWeed" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/InstantCWeed" target="_blank"><span class="text-dark">InstantCWeed</span><small class="ml-1x">Student</small></a></h3>
        <div>个人简介。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2020/05/01/%E5%B0%9A%E7%A1%85%E8%B0%B7Zookeeper%E7%AC%94%E8%AE%B0/" title="尚硅谷Zookeeper笔记"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2020/04/29/%E6%89%8B%E5%86%99%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E6%98%93%E7%9A%84LRU%E7%BC%93%E5%AD%98%E5%8E%9F%E7%90%86/" title="手写数据结构实现一个简易的LRU缓存原理"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>感谢您的支持，我会继续努力的!</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipaying.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpaying.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>



</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/InstantCWeed" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://weibo.com/u/3100744741" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="http://huaban.com/" target="_blank" title="Huaban" data-toggle=tooltip data-placement=top><i class="icon icon-huaban"></i></a></li>
        
        <li><a href="https://www.behance.net/" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>
<script src="/js/plugin.min.js"></script>
<script src="/js/application.js"></script>

    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>





   
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: '',
    appKey: '',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>

     







</body>
</html>